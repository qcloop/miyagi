{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retirement planning with Assistants API (GPTAssistantAgent)\n",
    "\n",
    "Using AutoGen's `GPTAssistantAgent`, this notebook demonstrates multi-agent retirement planning use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize autogen with configuration\n",
    "\n",
    "Use [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) to load a list of configurations from an environment variable or a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%pip -qqq install pyautogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import autogen\n",
    "from autogen.agentchat import AssistantAgent\n",
    "from autogen.agentchat.contrib.gpt_assistant_agent import GPTAssistantAgent\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define retirement planning agent swarm using GroupChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Define user proxy agent\n",
    "llm_config = {\"config_list\": config_list, \"cache_seed\": 45}\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"A user interested in retirement planning\",\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 2,\n",
    "        \"work_dir\": \"groupchat\",\n",
    "        \"use_docker\": False,\n",
    "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
    "    human_input_mode=\"TERMINATE\",\n",
    ")\n",
    "\n",
    "coder = GPTAssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    llm_config={\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    "    instructions=AssistantAgent.DEFAULT_SYSTEM_MESSAGE,\n",
    ")\n",
    "\n",
    "actuary = GPTAssistantAgent(\n",
    "    name=\"Actuary\",\n",
    "    instructions=\"You are an actuary. You are an expert in risk management and financial planning. You are here to help the user with their retirement planning.\",\n",
    "    llm_config={\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    ")\n",
    "\n",
    "estate_planner = GPTAssistantAgent(\n",
    "    name=\"Estate Planner\",\n",
    "    instructions=\"You are an estate planner. You are an expert in estate planning and wealth management. You are here to help the user with their retirement planning.\",\n",
    "    llm_config={\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    ")\n",
    "# define group chat\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, coder, actuary, estate_planner], messages=[], max_round=10)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate retirement planning\n",
    "Initiate multi-agent chat with a message to plan for retirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=\"I am 50 years old, expected to retire at 65, and have $500,000 in my retirement account. I want to know how much I need to save each month to retire comfortably.\",\n",
    ")\n",
    "# type exit to terminate the chat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
